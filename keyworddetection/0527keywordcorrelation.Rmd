---
title: "處理由keyword為seed的字詞相鄰矩陣"
author: "Bolun Lin"
date: "2019年5月23日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, paged.print=FALSE, r,echo=FALSE}
# pacman::p_load(dplyr,readr,tokenizers,ggplot2,tidytext,tidyr,ggraph,igraph,widyr,topicmodels,slam,MASS,wordcloud,randomcoloR,tm,qdap,textstem,corpus,data.table,stringr)
pacman::p_load(dplyr,readr,tm,slam,reshape2)
```

```{r}
# load data from python spacy
wind = read_csv("./wind_pos_new.csv") %>% data.frame
#修改後的keyword
key_word = read_csv("./keyword_new.csv")%>% data.frame
```


```{r}
# 修改ㄊkey_word表示形示
key_word =key_word %>%
  mutate(keyword = gsub(" ","_",word))

#找到包含keywor的sentence
filter_sen = sapply(key_word$keyword, function(x){
  grepl(x, wind$sentence ,fixed=T)
})
# 矩陣轉data.frame
filter_sen=as.data.frame(filter_sen)
# 找出要留下的句子
filter_sen = filter_sen %>%
  mutate(keep=rowSums(.)>=1)
# 篩選到wind資料，留下詞性為'NOUN'與'PROPN'，並組合成單一字串
keep_token = wind %>%
  filter(filter_sen$keep ==T) %>%
  filter(pos_ %in% c('NOUN','PROPN')) %>%
  group_by(sentence) %>%
  summarise(token_str = paste(lemma_,collapse=" "))

# t0 = Sys.time()
# mx = sapply(wind$sentence, str_detect, fixed(key_word$keyword, ignore_case=T)) %>% t
# Sys.time() - t0

```


```{r}

# 轉成 tdm
tdm = keep_token$token_str %>%
  VectorSource %>% Corpus %>% 
  tm_map(content_transformer(tolower)) %>% 
  # tm_map(toSpace,"\n") %>% 
  # tm_map(removePunctuation,preserve_intra_word_dashes = T) %>%
  tm_map(removeWords, c(stopwords("english"))) %>%
  # tm_map(lemmatize_strings)%>%
  # tm_map(stemDocument) %>% 
  TermDocumentMatrix() %>%
  removeSparseTerms(0.998)

inspect(tdm)
```

```{r}
# 轉成矩陣
termDocMatrix <- as.matrix(tdm)
as.data.frame(tdm)
# change it to a Boolean matrix
termDocMatrix[termDocMatrix>=1] <- 1
# transform into a term-term adjacency matrix
termMatrix <- termDocMatrix %*% t(termDocMatrix)
# 顯示keyword的pairwise相鄰矩陣
keywordMatrix=termMatrix[ row.names(termMatrix) %in% key_word$keyword ,colnames(termMatrix) %in% key_word$keyword]

```

```{r}
0.21820243 * 150
n=696; K=0.3
cx = cor(as(termMatrix[,1:n],"matrix"))
diag(cx) = 0
i = which(apply(cx,1,max) > K & apply(cx,2,max) > K)
cx[lower.tri(cx,T)] = 0
ex = cx[i,i]
colnames(ex) = rownames(ex) = 1:length(i)
edges = subset(melt(ex), value >= K)
edges$Source = names(i)[edges$Var1]
edges$Target = names(i)[edges$Var2]
edges$Type = "Undirected"
edges$Weight = edges$value
write.csv(edges[,4:7], "edges4.csv", quote=F, row.names=F,
          fileEncoding="utf-8")
```


